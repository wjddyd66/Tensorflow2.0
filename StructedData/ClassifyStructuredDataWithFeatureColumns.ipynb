{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify Structured data with feature columns\n",
    "Tensorflow 2.0에 맞게 다시 Tensorflow를 살펴볼 필요가 있다고 느껴져서 <a href=\"https://www.tensorflow.org/?hl=ko\">Tensorflow 정식 홈페이지</a>에 나와있는 예제부터 전반적인 Tensorflow 사용법을 먼저 익히는 Post가 된다.  \n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 필요한 Library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing\n",
    "**ML과 Deep Learning을 하면서 공통적으로 제일 중요하다고 생각하는 부분은 Data Preprocessing이다.**  \n",
    "어떻게 Data를 전처리 하냐에 따라서 같은 Model을 사용하더라도 성능차이는 많이 나게 된다.  \n",
    "따라서 Tensorflow 2.0 Tutorial에서도 이러한 Data를 3가지의 대표적인 유형으로 나누어서 소개하게 된다.  \n",
    "\n",
    "이번 Post Classify Structured data with feature columns는 구조화된 제일 기본적인 Data를 Keras를 사용하여 전처리 하는 Post가 된다.  \n",
    "이러한 Post는 4가지의 목표를 가지고 있다.  \n",
    "- <a href=\"https://wjddyd66.github.io/dataanalysis/Pandas/\">Pandas</a>를 사용하여 CSV 파일을 읽기\n",
    "- tf.data를 사용하여 행을 섞고 배치로 나누는 입력 파이프라인을 만들기\n",
    " - <a href=\"https://wjddyd66.github.io/tnesorflow2.0/Tensorflow2.0(3)/\">Load and preprocess Data</a>\n",
    " - <a href=\"https://wjddyd66.github.io/tnesorflow2.0/Tensorflow2.0(4)/\">Load and preprocess Data2</a>\n",
    "- CSV의 열을 feature_columns을 사용해 모델 훈련에 필요한 특성으로 매핑하기\n",
    "- 케라스를 사용하여 모델 구축, 훈련, 평가하기\n",
    "\n",
    "**참고**  \n",
    "이번 Post는 위의 링크인 Load and preprocess Data1, 2와 많은 부분이 겹치게 됩니다.  \n",
    "복습하는 차원에서 다시 한번 정리하는 Post이므로 위의 링크를 보시고 이해가 되신 분들은 이번 Post는 넘기셔도 됩니다.  \n",
    "<br><br>\n",
    "\n",
    "#### The Dataset\n",
    "<a href=\"https://archive.ics.uci.edu/ml/datasets/heart+Disease\">Cleveland Clinic Foundation for Heart Disease</a>의 Dataset을 사용하게 됩니다.  \n",
    "각각의 Dataset은 다음과 같은 특성을 가지게 됩니다.  \n",
    "중요한점은 수치형과 범주형 열이 모두 존재한다는 것 이다.  \n",
    "\n",
    "- 범주형(Categorical Data): 몇 개의 범주로 나누어 진 자료 ex) 남/여, 성공/실패\n",
    " - 명목형 자료: 순서와 상관 없는 자료(단순한 분류)\n",
    " - 순서형 자료: 순서와 상관 있는 자료\n",
    "- 수치형(Numerical Data)\n",
    " - 이산형 자료: 이산적인 값을 갖는 데이터\n",
    " - 연속형 자료: 연속적인 값을 갖는 데이터\n",
    "\n",
    "<div class=\"devsite-table-wrapper\"><table>\n",
    "<thead>\n",
    "<tr>\n",
    "<th>Column</th>\n",
    "<th>Description</th>\n",
    "<th>Feature Type</th>\n",
    "<th>Data Type</th>\n",
    "</tr>\n",
    "</thead>\n",
    "\n",
    "<tbody>\n",
    "<tr>\n",
    "<td>Age</td>\n",
    "<td>Age in years</td>\n",
    "<td>Numerical</td>\n",
    "<td>integer</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Sex</td>\n",
    "<td>(1 = male; 0 = female)</td>\n",
    "<td>Categorical</td>\n",
    "<td>integer</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>CP</td>\n",
    "<td>Chest pain type (0, 1, 2, 3, 4)</td>\n",
    "<td>Categorical</td>\n",
    "<td>integer</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Trestbpd</td>\n",
    "<td>Resting blood pressure (in mm Hg on admission to the hospital)</td>\n",
    "<td>Numerical</td>\n",
    "<td>integer</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Chol</td>\n",
    "<td>Serum cholestoral in mg/dl</td>\n",
    "<td>Numerical</td>\n",
    "<td>integer</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>FBS</td>\n",
    "<td>(fasting blood sugar &gt; 120 mg/dl) (1 = true; 0 = false)</td>\n",
    "<td>Categorical</td>\n",
    "<td>integer</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>RestECG</td>\n",
    "<td>Resting electrocardiographic results (0, 1, 2)</td>\n",
    "<td>Categorical</td>\n",
    "<td>integer</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Thalach</td>\n",
    "<td>Maximum heart rate achieved</td>\n",
    "<td>Numerical</td>\n",
    "<td>integer</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Exang</td>\n",
    "<td>Exercise induced angina (1 = yes; 0 = no)</td>\n",
    "<td>Categorical</td>\n",
    "<td>integer</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Oldpeak</td>\n",
    "<td>ST depression induced by exercise relative to rest</td>\n",
    "<td>Numerical</td>\n",
    "<td>float</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Slope</td>\n",
    "<td>The slope of the peak exercise ST segment</td>\n",
    "<td>Numerical</td>\n",
    "<td>integer</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>CA</td>\n",
    "<td>Number of major vessels (0-3) colored by flourosopy</td>\n",
    "<td>Numerical</td>\n",
    "<td>integer</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Thal</td>\n",
    "<td>3 = normal; 6 = fixed defect; 7 = reversable defect</td>\n",
    "<td>Categorical</td>\n",
    "<td>string</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Target</td>\n",
    "<td>Diagnosis of heart disease (1 = true; 0 = false)</td>\n",
    "<td>Classification</td>\n",
    "<td>integer</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table></div>\n",
    "<br><br>\n",
    "\n",
    "#### Use Pandas to create a dataframe\n",
    "Pandas를 활용하여 위의 Dataset을 Dataframe형태로 변현한다.  \n",
    "\n",
    "**참고(Request Error)**  \n",
    "현재 Tensorflow 2.0에서 제공하는 Code를 그대로 사용하는 경우 Request Error가 발생하게 된다.  \n",
    "Pandas Version Error인지 Jupyter Notebook의 Ipython Error인지는 파악되지 않으나 <a href=\"https://stackoverflow.com/questions/32400867/pandas-read-csv-from-url\">Stack Overflow</a>를 참조하여 Code를 아래와 같이 변경하여 해결하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>fixed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>reversible</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   1       145   233    1        2      150      0      2.3      3   \n",
       "1   67    1   4       160   286    0        2      108      1      1.5      2   \n",
       "2   67    1   4       120   229    0        2      129      1      2.6      2   \n",
       "3   37    1   3       130   250    0        0      187      0      3.5      3   \n",
       "4   41    0   2       130   204    0        2      172      0      1.4      1   \n",
       "\n",
       "   ca        thal  target  \n",
       "0   0       fixed       0  \n",
       "1   3      normal       1  \n",
       "2   2  reversible       0  \n",
       "3   0      normal       0  \n",
       "4   0      normal       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URL = 'https://storage.googleapis.com/applied-dl/heart.csv'\n",
    "# Download and read Dataset\n",
    "x = requests.get(url=URL).content \n",
    "dataframe = pd.read_csv(io.StringIO(x.decode('utf8')))\n",
    "# Top 5 Data Check\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the dataframe into train, validation, and test\n",
    "위에서 선언한 Dataframe을 활용하여 Model에 필요한 Train, Validation, and Test Dataset으로서 sklearn을 활용하여 Split을 하게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193 train examples\n",
      "49 validation examples\n",
      "61 test examples\n"
     ]
    }
   ],
   "source": [
    "# Split the dataframe into train, validation, and test\n",
    "train, test = train_test_split(dataframe,test_size=0.2)\n",
    "train, val = train_test_split(train,test_size=0.2)\n",
    "\n",
    "# Check the Split Data\n",
    "print(len(train),'train examples')\n",
    "print(len(val),'validation examples')\n",
    "print(len(test),'test examples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create an input pipeline using tf.data\n",
    "tf.data를 활용하여 Feature, Label로서 나누고 Batch처리 까지 진행하게 된다. Model의 성능을 향상시키기 위하여 Train Dataset의 경우에는 Shuffle까지 진행하게 된다.  \n",
    "\n",
    "아래 Code가 이해되지 않으면 밑의 두 링크를 참조하도록 하자.  \n",
    "- <a href=\"https://wjddyd66.github.io/tnesorflow2.0/Tensorflow2.0(3)/\">Load and preprocess Data</a>\n",
    "- <a href=\"https://wjddyd66.github.io/tnesorflow2.0/Tensorflow2.0(4)/\">Load and preprocess Data2</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every Feature:  ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal']\n",
      "A batch of ages:  tf.Tensor([61 64 57 41 63], shape=(5,), dtype=int32)\n",
      "A batch of targets:  tf.Tensor([0 1 0 0 1], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "    dataframe = dataframe.copy()\n",
    "    # Pop Label\n",
    "    labels = dataframe.pop('target')\n",
    "    # Datafrmae to Tensor\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe),labels))\n",
    "    # Shuffle Tensor\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size = len(dataframe))\n",
    "    # Batch Tensor\n",
    "    ds = ds.batch(batch_size)\n",
    "    return ds\n",
    "\n",
    "batch_size = 5\n",
    "# Train Data with Shuffle\n",
    "train_ds = df_to_dataset(train,batch_size=batch_size)\n",
    "# Validation Data, Test Data with no shuffle\n",
    "val_ds = df_to_dataset(val,shuffle=False,batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test,shuffle=False,batch_size=batch_size)\n",
    "\n",
    "# Check Tensor\n",
    "for feature_batch, label_batch in train_ds.take(1):\n",
    "    print('Every Feature: ',list(feature_batch.keys()))\n",
    "    print('A batch of ages: ', feature_batch['age'])\n",
    "    print('A batch of targets: ',label_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demonstrate several types of feature column\n",
    "train_ds를 계속하여 Input으로 넣으나, <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/DenseFeatures\">tf.keras.layers.DenseFeatures</a>를 사용하여 Feature Columns가 어떻게 변형되는지 살펴본다.  \n",
    "즉, 원하는 Dataframe의 Column을 Input으로 넣어서 어떻게 DenseFeaures로 표현되는지 살펴본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this batch to demonstrate several types of feature columns\n",
    "example_batch = next(iter(train_ds))[0] # Not use Label\n",
    "\n",
    "# Create a Feature column and transform a batch of data\n",
    "def demo(feature_column):\n",
    "    feature_layer = layers.DenseFeatures(feature_column)\n",
    "    print(feature_layer(example_batch).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numeric columns\n",
    "가장 간단한 Numeric columns이다. 기본적인 Input Data를 그대로 표현하여 나타내는 것 이다.  \n",
    "참조: <a href=\"https://www.tensorflow.org/api_docs/python/tf/feature_column/numeric_column\">tf.feature_column.numeric_column 사용법</a>  \n",
    "참조: Option을 사용하여 Data의 수치를 바로 변경하는 것이 가능하다.(즉, 평균과 분산을 알게 되면 Normalization을 바로 적용시킬 수 있다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check NUmeric Column\n",
      "[[66.]\n",
      " [63.]\n",
      " [51.]\n",
      " [40.]\n",
      " [46.]]\n",
      "\n",
      "Check Option\n",
      "[[63.]\n",
      " [60.]\n",
      " [48.]\n",
      " [37.]\n",
      " [43.]]\n"
     ]
    }
   ],
   "source": [
    "# Ignore Warning Change Backend to float 64\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "\n",
    "# Check Numeric Column\n",
    "age = feature_column.numeric_column('age')\n",
    "print('Check NUmeric Column')\n",
    "demo(age)\n",
    "print()\n",
    "\n",
    "# Check Option\n",
    "normalizer_function = lambda x:(x-3)\n",
    "age = feature_column.numeric_column('age',normalizer_fn=normalizer_function)\n",
    "print('Check Option')\n",
    "demo(age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bucketized columns\n",
    "위와 같은 Numeric한 수치를 바로 넣는 것이 아니라 일정한 버킷(Bucket)으로 나눌 수 있다.  \n",
    "즉, 일정한 번위안의 속하면 1, 아니면 0 으로서 One-Hot-Encoding형식으로서 나타내어 Bucketized Columns로 나타낼 수 있다.  \n",
    "참조: <a href=\"https://www.tensorflow.org/api_docs/python/tf/feature_column/bucketized_column\">tf.feature_column.bucketized_column 사용법</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "age_buckets = feature_column.bucketized_column(age,boundaries=[18,25,30,40,45,50,55,60,65])\n",
    "demo(age_buckets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical columns\n",
    "범주형 데이터(Cateforical Data)의 경우 Model의 Input으로 넣기 위하여 수치형 데이터(Numerical Data)로 변경하여야 한다.  \n",
    "위의 Bucketized columns와 마찬가지로서 Category에 따라서 One-Hot-Encoidng으로서 나타낸다.  \n",
    "\n",
    "참조: <a href=\"https://www.tensorflow.org/api_docs/python/tf/feature_column/indicator_column\">tf.feature_column.indicator_column</a>: 기본적으로 Categorical Column을 Input으로 넣기 위해서는 <code>.indicator_column</code>가 필요하다.  \n",
    "참조: <a href=\"https://www.tensorflow.org/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_list\">tf.feature_column.catrgorical_column_with_vocabulary_list 사용법(List로서 전달)</a><br>\n",
    "참조: <a href=\"https://www.tensorflow.org/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file\">tf.feature_column.catrgorical_column_with_vocabulary_file 사용법(File로서 전달)</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thal Catrgory\n",
      "{'1', 'normal', 'reversible', 'fixed', '2'}\n",
      "\n",
      "[[0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Check Categorical Value\n",
    "thal_category = set(dataframe['thal'])\n",
    "print('Thal Catrgory')\n",
    "print(thal_category)\n",
    "print()\n",
    "\n",
    "# Categorical Columns -> Numeric Tensor\n",
    "thal = feature_column.categorical_column_with_vocabulary_list('thal',['fixed','normal','reversible','1','2'])\n",
    "thal_one_hot = feature_column.indicator_column(thal)\n",
    "demo(thal_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding columns\n",
    "Category의 수가 매우 많아지게 되었을 경우 One-Hot-Encoding으로서 나타내는 것은 Resource를 많이 낭비하게 되고, Computing Power가 버티지 못할 확률이 매우 높아진다.  \n",
    "따라서 Embedding Columns로서 나타내는 것이 필요하다.  \n",
    "개인적인 경험으로는 이러한 Embedding Layer는 자연어 분야에서 Vocab File의 전처리를 위하여 많이 사용되는 것으로 알 고 있다.  \n",
    "\n",
    "참조: <a href=\"https://wjddyd66.github.io/dl/Fast-word2vec/#embedding-계층\">Embedding 자세한 내용</a><br>\n",
    "참조: <a href=\"https://www.tensorflow.org/api_docs/python/tf/feature_column/embedding_column\">tf.feature_column.embedding_column 사용법</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.04294701  0.6549929   0.1659287 ]\n",
      " [-0.04294701  0.6549929   0.1659287 ]\n",
      " [-0.04294701  0.6549929   0.1659287 ]\n",
      " [ 0.6932911   0.52152395 -0.26704228]\n",
      " [-0.04294701  0.6549929   0.1659287 ]]\n"
     ]
    }
   ],
   "source": [
    "thal_embedding = feature_column.embedding_column(thal,dimension=3)\n",
    "demo(thal_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hashed feature columns\n",
    "위와 같이 많은 Category의 수를 줄이기 위한 방법으로서 Hash Feature Columns를 사용하는 방법이 있다.  \n",
    "**하지만, 어떻게 Hash를 할당하는 지는 자세히 모르겠으며, 다른 문자열이 같은 Bucket에 할당 될 수 있는 매우 큰 단점이 존재하나, 일부 데이터셋 에서 잘 작동한다고 한다.**  \n",
    "참조: <a href=\"https://www.tensorflow.org/api_docs/python/tf/feature_column/categorical_column_with_hash_bucket\">tf.feature_column.categorical_column_with_hash_bucket 사용법</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "thal_hashed = feature_column.categorical_column_with_hash_bucket(\n",
    "      'thal', hash_bucket_size=2)\n",
    "demo(feature_column.indicator_column(thal_hashed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crossed Feature columns\n",
    "여러 특성을 연결하여 하나의 특성으로 만드는 것을 feature cross라고 한다.  \n",
    "모델이 특성의 조합에 대한 가중치를 학습할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thal Catrgory\n",
      "{'1', 'normal', 'reversible', 'fixed', '2'}\n",
      "\n",
      "Age bucket\n",
      "(18, 25, 30, 35, 40, 45, 50, 55, 60, 65)\n",
      "\n",
      "[[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Check Thal's Categorical Value\n",
    "thal_category = set(dataframe['thal'])\n",
    "print('Thal Catrgory')\n",
    "print(thal_category)\n",
    "print()\n",
    "\n",
    "# Check Age bucket\n",
    "print(\"Age bucket\")\n",
    "print(age_buckets.boundaries)\n",
    "print()\n",
    "\n",
    "crossed_feature = feature_column.crossed_column([age_buckets,thal],hash_bucket_size=10)\n",
    "demo(feature_column.indicator_column(crossed_feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose which columns to use\n",
    "실제 Dataframe에서 사용할 Columns를 선택하여 Input Tensor로서 변형하기 위한 과정이다.  \n",
    "Numeric Data, Bucketized Column(Age), Categorical Column(Thal)을 위에서 설명한 전처리 과정으로서 Data Preprocessing Layer를 추가하여 실제 Model의 Input으로서 사용하기 위한 Layer를 선언하는 방법이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = []\n",
    "\n",
    "# numeric cols\n",
    "for header in ['age', 'trestbps', 'chol', 'thalach', 'oldpeak', 'slope', 'ca']:\n",
    "    feature_columns.append(feature_column.numeric_column(header))\n",
    "\n",
    "# bucketized cols\n",
    "age_buckets = feature_column.bucketized_column(age, boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65])\n",
    "feature_columns.append(age_buckets)\n",
    "\n",
    "# indicator cols\n",
    "thal = feature_column.categorical_column_with_vocabulary_list(\n",
    "      'thal', ['fixed', 'normal', 'reversible','1','2'])\n",
    "thal_one_hot = feature_column.indicator_column(thal)\n",
    "feature_columns.append(thal_one_hot)\n",
    "\n",
    "# Create Feature Layer\n",
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Model & Train & Test\n",
    "위에서 선언한 Data Preprocessing Layer 를 사용하여 실제 Model에 넣고 정확도까지 확인하는 과정 이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 39 steps, validate for 10 steps\n",
      "Epoch 1/10\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 6.0396 - accuracy: 0.6218 - val_loss: 1.2359 - val_accuracy: 0.7755\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 1.4230 - accuracy: 0.6891 - val_loss: 1.2503 - val_accuracy: 0.6735\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.7141 - accuracy: 0.7513 - val_loss: 1.5309 - val_accuracy: 0.5714\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 1.4310 - accuracy: 0.6736 - val_loss: 0.8234 - val_accuracy: 0.7143\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.6450 - accuracy: 0.7720 - val_loss: 0.6224 - val_accuracy: 0.7551\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.6200 - accuracy: 0.7513 - val_loss: 0.5520 - val_accuracy: 0.7755\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.6343 - accuracy: 0.7202 - val_loss: 0.7297 - val_accuracy: 0.7959\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.8828 - accuracy: 0.6891 - val_loss: 0.8319 - val_accuracy: 0.7347\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.6719 - accuracy: 0.7720 - val_loss: 1.8141 - val_accuracy: 0.4694\n",
      "Epoch 10/10\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 0.7413 - accuracy: 0.7306 - val_loss: 0.5578 - val_accuracy: 0.7755\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8657 - accuracy: 0.7541\n",
      "Accuracy 0.75409836\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    feature_layer,\n",
    "    layers.Dense(128,activation='relu'),\n",
    "    layers.Dense(128,activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_ds,\n",
    "         validation_data = val_ds,\n",
    "         epochs = 10)\n",
    "\n",
    "loss,accuracy = model.evaluate(test_ds)\n",
    "print('Accuracy',accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
