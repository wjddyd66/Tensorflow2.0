{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimators\n",
    "Tensorflow 2.0에 맞게 다시 Tensorflow를 살펴볼 필요가 있다고 느껴져서 <a href=\"https://www.tensorflow.org/?hl=ko\">Tensorflow 정식 홈페이지</a>에 나와있는 예제부터 전반적인 Tensorflow 사용법을 먼저 익히는 Post가 된다.  \n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 필요한 Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from six.moves import urllib\n",
    "import tensorflow.compat.v2.feature_column as fc\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is Estimators?\n",
    "**추상화(abstraction)** 이란 코드를 특정한 목적으로 일반화하여 기존 코드 '위에 올라가는' 코드의 계층을 의미한다. 관련있는 High-Level 기능을 묶는 방식의 재구성을 통해 코드를 감싸서 추상화한다. 따라서 쉽게 코딩할 수 있고, 가독성이 좋으며, 코드가 간소화된다.  \n",
    "이러한 추상화 라이브러리를 살펴보면 다음과 같은 종류들이 존재한다.\n",
    "- **tf.estimator**\n",
    "- TFLearn\n",
    "- TF-Slim\n",
    "- Keras\n",
    "\n",
    "tf.estimator또한 Keras와 같이 관련있는 High-Level 기능을 묶는 방식의 재구성을 통해 Code를 추상화하는 방법이다.  \n",
    "익숙한 Keras를 예를 들어 설명하면 <code>tf.keras.Model</code>또한 model-level abstraction이다.  \n",
    "출처: <a href=\"https://excelsior-cjh.tistory.com/157\">excelsior-cjh 블로그</a><br>\n",
    "\n",
    "이러한 High-Level Tensorflow API인 **tf.estimator**는 다음과 같은 기능들을 포함하고 있습니다.\n",
    "- training\n",
    "- evaluation\n",
    "- prediction\n",
    "- export for serving\n",
    "\n",
    "이러한 Estimator는 미리 만들어진 것을 사용하거나 사용자가 직접 정의하여 Customizing한 것을 사용할 수 있다.  \n",
    "<br><br>\n",
    "\n",
    "#### Estimators Capabilities\n",
    "Estimators에 대한 장점을 다음과 같이 설명하고 있다.  \n",
    ">1. Model을 변경하지 않고 호스트 또는 분산 다중 서버 환경에서 Estimator 기반 모델을 실행할 수 있다. 또한 모델을 코딩하지 않고도 CPU, GPU 또는 TPU에서 Estimator 기반 모델을 실행 할 수 있다.\n",
    "2. Estimator는 다음과 같은 safe distributed training loop를 제공한다.\n",
    " - load data\n",
    " - handel exceptions\n",
    " - create checkpoint files and recover from failures\n",
    " - save summaries for TensorBoard\n",
    ">\n",
    "\n",
    "<br><br>\n",
    "\n",
    "### Premade Estimators\n",
    "이미 정의 되어있는 Estimators를 활용하여 Iris Classification Problem을 해결한다.  \n",
    "또한 Estimators를 Programming하는 방법으로는 다음과 같이 설명하고 있다.\n",
    "1. Create one or more input function\n",
    "2. Define the model's feature columns\n",
    "3. Instantiate an Estimator, specifying the feature columns and various hyperparameters.\n",
    "4. Call one or more methods on the Estimator object, passing the appropriate input function as the source of the data.\n",
    "\n",
    "위와 같이 정의된 Estimaros에 대하여 학습 데이터를 사용해 모델을 학습(Training): <code>model.(train)</code> -> 학습된 모델을 평가(evaluate): <code>model.evaluate()</code> -> 테스트 데이터를 이용해 결과를 예측(predict): <code>model.predict()</code>는 기존의 Model들과 동일하다.\n",
    "\n",
    "\n",
    "참고사항으로, Tensorflow 2.0에서도 Keras API에서도 같은 수행을 할 수 있는 것이 많다고 한다. 새로 시작하는 사람들은 Keras로 시작하는 것을 추천하고 있다.  \n",
    "<br>\n",
    "\n",
    "#### Iris Dataset 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SepalLength  SepalWidth  PetalLength  PetalWidth  Species\n",
      "0          6.4         2.8          5.6         2.2        2\n",
      "1          5.0         2.3          3.3         1.0        1\n",
      "2          4.9         2.5          4.5         1.7        2\n",
      "3          4.9         3.1          1.5         0.1        0\n",
      "4          5.7         3.8          1.7         0.3        0\n"
     ]
    }
   ],
   "source": [
    "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n",
    "SPECIES = ['Setosa', 'Versicolor', 'Virginica']\n",
    "\n",
    "train_path = tf.keras.utils.get_file(\n",
    "    \"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
    "test_path = tf.keras.utils.get_file(\n",
    "    \"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n",
    "\n",
    "train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "\n",
    "print(train.head())\n",
    "\n",
    "train_y = train.pop('Species')\n",
    "test_y = test.pop('Species')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create input functions\n",
    "- input_evaluation_set(): 초기 자료값 선언\n",
    "- input_fn(): features(Data), labels를 받아서 Tensor로 바꾸는 작업 각각의 Feature들은 Dict Type으로서 형성되고 labels들은 Tensor로서 선언된다. 아래 Code의 주석을 해제하고 실행하게 되면 다음과 같은 결과를 얻게 된다.\n",
    "\n",
    "```code\n",
    "{'SepalLength': <tf.Tensor: id=1938, shape=(3,), dtype=float64, numpy=array([6.4, 5. , 4.9])>, 'SepalWidth': <tf.Tensor: id=1939, shape=(3,), dtype=float64, numpy=array([2.8, 2.3, 2.5])>, 'PetalLength': <tf.Tensor: id=1936, shape=(3,), dtype=float64, numpy=array([5.6, 3.3, 4.5])>, 'PetalWidth': <tf.Tensor: id=1937, shape=(3,), dtype=float64, numpy=array([2.2, 1. , 1.7])>}\n",
    "tf.Tensor([2 1 2], shape=(3,), dtype=int32)\n",
    "```\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# input_fn 확인\\nexample = input_fn(train[0:3],train_y[0:3],training=False,batch_size=3)\\n\\nfor train,label in example:\\n    print(train)\\n    print(label)\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def input_evaluation_set():\n",
    "    features = {'SepalLength': np.array([6.4, 5.0]),\n",
    "                'SepalWidth':  np.array([2.8, 2.3]),\n",
    "                'PetalLength': np.array([5.6, 3.3]),\n",
    "                'PetalWidth':  np.array([2.2, 1.0])}\n",
    "    labels = np.array([2, 1])\n",
    "    return features, labels\n",
    "\n",
    "def input_fn(features, labels, training=True, batch_size=256):\n",
    "    \"\"\"An input function for training or evaluating\"\"\"\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "\n",
    "    # Shuffle and repeat if you are in training mode.\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(1000).repeat()\n",
    "    \n",
    "    return dataset.batch(batch_size)\n",
    "\n",
    "'''\n",
    "# input_fn 확인\n",
    "example = input_fn(train[0:3],train_y[0:3],training=False,batch_size=3)\n",
    "\n",
    "for train,label in example:\n",
    "    print(train)\n",
    "    print(label)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the feature columns\n",
    "Model에서 Data로 들어오는 것에서의 특정 Feature를 찾는 단계이다.  \n",
    "<code>tf.feature_column.numeric_column(key=key)</code>를 통하여 Input으로 들어오는 Dict Type{'feature': Tensor}중 Numeric Type의 Tensor에 대한 정보를 my_feature_columns에 추가한다.  \n",
    "위와 같은 <code>tf.feature_column.numeric_column()</code>을 사용하게 되면 다양한 형태의 Data를 쉽게 변환 가능하다.  \n",
    "예를 들어 범주형(categorical) 데이터를 Sparse Vector 즉, one-hot 인코딩 해주며, 또는 수치형 데이터를 구간별로 버킷화 한 뒤 더미 인코딩을 실시한다.  \n",
    "\n",
    "**<code>categorical_column_with_vocabulary_list()</code> 사용예시**  \n",
    "위의 Code는 범주형(categorical) 변수를 one-hot Vector로서 Mapping하는데 사용된다.  \n",
    "<img srcset=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=http%3A%2F%2Fcfile6.uf.tistory.com%2Fimage%2F99B849475B359FBC364DB3\" src=\"https://t1.daumcdn.net/cfile/tistory/99B849475B359FBC36\"><br>\n",
    "사진 출처: <a href=\"https://excelsior-cjh.tistory.com/157\">excelsior-cjh 블로그</a><br>\n",
    "자세한 사항은 다음 Post에서 다룬다.  \n",
    "참조: <a href=\"https://www.tensorflow.org/api_docs/python/tf/feature_column/numeric_column?version=stable\">tf.feature_column.numeric_column() 설명서</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
     ]
    }
   ],
   "source": [
    "# Feature columns describe how to use the input.\n",
    "my_feature_columns = []\n",
    "for key in train.keys():\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
    "print(my_feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate an estimator\n",
    "미리 정의되어 있는 <code>tf.estimator.DNNClassifier()</code>를 통하여 Estimator Object를 선언한다. 각각의 Argument는 다음의 의미를 가지고 있다.\n",
    "- feature_columns: 사용할 Feature\n",
    "- hidden_uints: Hidden Layer 선언 ex) <code>hidden_units=[30, 10]</code>를 Diemnsion관점으로 살펴보게 되면 Input -> Dense(30) -> Dense(10)으로서 선언된다.\n",
    "- n_classes: 최종적인 Output의 Dimension(현재 Species가 3개이므로 3으로서 선언한다.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp7eot2fe3\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp7eot2fe3', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9779081110>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Build a DNN with 2 hidden layers with 30 and 10 hidden nodes each.\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=my_feature_columns,\n",
    "    # Two hidden layers of 30 and 10 nodes respectively.\n",
    "    hidden_units=[30, 10],\n",
    "    # The model must choose between 3 classes.\n",
    "    n_classes=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train, Evaluate, and Predict\n",
    "위에서 선언한 Estimater를 활용하여 실제 Model을 구성하고 Train 및 Prediction까지 실시한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /root/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:From /root/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/adagrad.py:108: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp7eot2fe3/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.6977032, step = 0\n",
      "INFO:tensorflow:global_step/sec: 340.353\n",
      "INFO:tensorflow:loss = 1.1159577, step = 100 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 506.065\n",
      "INFO:tensorflow:loss = 1.0721594, step = 200 (0.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 484.153\n",
      "INFO:tensorflow:loss = 1.0436205, step = 300 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 437.044\n",
      "INFO:tensorflow:loss = 1.0180271, step = 400 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 435.779\n",
      "INFO:tensorflow:loss = 1.0070751, step = 500 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 375.911\n",
      "INFO:tensorflow:loss = 0.9851279, step = 600 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 362.479\n",
      "INFO:tensorflow:loss = 0.971541, step = 700 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 374.509\n",
      "INFO:tensorflow:loss = 0.9559419, step = 800 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 437.797\n",
      "INFO:tensorflow:loss = 0.9423557, step = 900 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 482.024\n",
      "INFO:tensorflow:loss = 0.9283109, step = 1000 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 430.182\n",
      "INFO:tensorflow:loss = 0.91715604, step = 1100 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 379.92\n",
      "INFO:tensorflow:loss = 0.9021194, step = 1200 (0.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 444.759\n",
      "INFO:tensorflow:loss = 0.89815754, step = 1300 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 493.11\n",
      "INFO:tensorflow:loss = 0.87750375, step = 1400 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 500.455\n",
      "INFO:tensorflow:loss = 0.8661442, step = 1500 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 479.869\n",
      "INFO:tensorflow:loss = 0.8503312, step = 1600 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 476.717\n",
      "INFO:tensorflow:loss = 0.83737016, step = 1700 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 401.452\n",
      "INFO:tensorflow:loss = 0.8287333, step = 1800 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 393.67\n",
      "INFO:tensorflow:loss = 0.80942833, step = 1900 (0.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 486.438\n",
      "INFO:tensorflow:loss = 0.80888635, step = 2000 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 490.56\n",
      "INFO:tensorflow:loss = 0.79143083, step = 2100 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 443.073\n",
      "INFO:tensorflow:loss = 0.785636, step = 2200 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 481.303\n",
      "INFO:tensorflow:loss = 0.77415735, step = 2300 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 488.729\n",
      "INFO:tensorflow:loss = 0.7597798, step = 2400 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.615\n",
      "INFO:tensorflow:loss = 0.74340886, step = 2500 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 484.693\n",
      "INFO:tensorflow:loss = 0.7433095, step = 2600 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 491.065\n",
      "INFO:tensorflow:loss = 0.72283566, step = 2700 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 453.057\n",
      "INFO:tensorflow:loss = 0.7176484, step = 2800 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 506.138\n",
      "INFO:tensorflow:loss = 0.7047235, step = 2900 (0.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.125\n",
      "INFO:tensorflow:loss = 0.6974204, step = 3000 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.113\n",
      "INFO:tensorflow:loss = 0.68672264, step = 3100 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.29\n",
      "INFO:tensorflow:loss = 0.68201745, step = 3200 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.216\n",
      "INFO:tensorflow:loss = 0.66798764, step = 3300 (0.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.448\n",
      "INFO:tensorflow:loss = 0.66435325, step = 3400 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.265\n",
      "INFO:tensorflow:loss = 0.6496955, step = 3500 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.88\n",
      "INFO:tensorflow:loss = 0.6434547, step = 3600 (0.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.367\n",
      "INFO:tensorflow:loss = 0.63857967, step = 3700 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 395.381\n",
      "INFO:tensorflow:loss = 0.6245391, step = 3800 (0.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.243\n",
      "INFO:tensorflow:loss = 0.6219383, step = 3900 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 391.219\n",
      "INFO:tensorflow:loss = 0.6176598, step = 4000 (0.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 396.24\n",
      "INFO:tensorflow:loss = 0.58445, step = 4100 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 393.046\n",
      "INFO:tensorflow:loss = 0.5675239, step = 4200 (0.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 401.251\n",
      "INFO:tensorflow:loss = 0.55745155, step = 4300 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 432.314\n",
      "INFO:tensorflow:loss = 0.5572114, step = 4400 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 440.574\n",
      "INFO:tensorflow:loss = 0.54766005, step = 4500 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 414.376\n",
      "INFO:tensorflow:loss = 0.5319838, step = 4600 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 449.023\n",
      "INFO:tensorflow:loss = 0.53427553, step = 4700 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 474.125\n",
      "INFO:tensorflow:loss = 0.5276116, step = 4800 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.265\n",
      "INFO:tensorflow:loss = 0.5358479, step = 4900 (0.339 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tmp7eot2fe3/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.51131165.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-12-28T13:48:24Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp7eot2fe3/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2019-12-28-13:48:24\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.8333333, average_loss = 0.591617, global_step = 5000, loss = 0.591617\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: /tmp/tmp7eot2fe3/model.ckpt-5000\n",
      "\n",
      "Test set accuracy: 0.833\n",
      "\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp7eot2fe3/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Prediction is \"Setosa\" (68.4%), expected \"Setosa\"\n",
      "Prediction is \"Virginica\" (45.0%), expected \"Versicolor\"\n",
      "Prediction is \"Virginica\" (60.6%), expected \"Virginica\"\n"
     ]
    }
   ],
   "source": [
    "# Train the Model.\n",
    "classifier.train(input_fn=lambda: input_fn(train, train_y, training=True),steps=5000)\n",
    "\n",
    "# Evaluate the trained model\n",
    "eval_result = classifier.evaluate(input_fn=lambda: input_fn(test, test_y, training=False))\n",
    "\n",
    "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))\n",
    "\n",
    "# Making predictions (inferring) from the trained model\n",
    "# Generate predictions from the model\n",
    "expected = ['Setosa', 'Versicolor', 'Virginica']\n",
    "predict_x = {\n",
    "    'SepalLength': [5.1, 5.9, 6.9],\n",
    "    'SepalWidth': [3.3, 3.0, 3.1],\n",
    "    'PetalLength': [1.7, 4.2, 5.4],\n",
    "    'PetalWidth': [0.5, 1.5, 2.1],\n",
    "}\n",
    "\n",
    "def input_fn(features, batch_size=256):\n",
    "    \"\"\"An input function for prediction.\"\"\"\n",
    "    # Convert the inputs to a Dataset without labels.\n",
    "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
    "\n",
    "predictions = classifier.predict(\n",
    "    input_fn=lambda: input_fn(predict_x))\n",
    "\n",
    "for pred_dict, expec in zip(predictions, expected):\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id]\n",
    "\n",
    "    print('Prediction is \"{}\" ({:.1f}%), expected \"{}\"'.format(\n",
    "        SPECIES[class_id], 100 * probability, expec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a linear model with Estimators\n",
    "Estimators를 활용하여 Linear한 Model을 Build하는 과정이다.  \n",
    "하나의 end-to-end wlakthrough trains a logistic regression model을 Build하는 과정이라고 생가하면 된다.  \n",
    "<br>\n",
    "\n",
    "#### Load he titanic dataset\n",
    "Titanid dataset을 다운받고 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset.\n",
    "dftrain = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv')\n",
    "dfeval = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv')\n",
    "\n",
    "# Label 설정\n",
    "y_train = dftrain.pop('survived')\n",
    "y_eval = dfeval.pop('survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore the Data\n",
    "Pandas로 이루워진 Dataset에 대한 전반적인 정보를 확인하는 방법에 대해서 알아본다.\n",
    "- <code>.head()</code>: 상위 몇 개에 대한 Dataset을 확인한다.\n",
    "- <code>.describe()</code>: Numberic Feature들의 상세 정보를 출력해준다.\n",
    "- <code>.shape()</code>: Dataset의 Shape를 출려한다.\n",
    "- <code>.hist(), .plot()</code>: Matplotlib형식 으로서 결과를 Visualization한다.\n",
    "- <code>.value_counts()</code>: Data의 Value별로 Counts를 계산한다.\n",
    "\n",
    "Pandas란 파이썬에서 사용하는 데이터 분석 라이므러리로서 꼭 알고 지나가야하는 도구 입니다.  \n",
    "Pandas에 대하여 사전지식이 없으신 분들은 아래 링크를 참조하시길 바랍니다.  \n",
    "참조: <a href=\"https://wjddyd66.github.io/dataanalysis/Pandas/\">Pandas</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 확인\n",
      "      sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
      "0    male  22.0                   1      0   7.2500  Third  unknown   \n",
      "1  female  38.0                   1      0  71.2833  First        C   \n",
      "2  female  26.0                   0      0   7.9250  Third  unknown   \n",
      "3  female  35.0                   1      0  53.1000  First        C   \n",
      "4    male  28.0                   0      0   8.4583  Third  unknown   \n",
      "\n",
      "   embark_town alone  \n",
      "0  Southampton     n  \n",
      "1    Cherbourg     n  \n",
      "2  Southampton     y  \n",
      "3  Southampton     n  \n",
      "4   Queenstown     y  \n",
      "\n",
      "Label 확인\n",
      "0    0\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    0\n",
      "Name: survived, dtype: int64\n",
      "\n",
      "Dataset 상세 정보 확인\n",
      "              age  n_siblings_spouses       parch        fare\n",
      "count  627.000000          627.000000  627.000000  627.000000\n",
      "mean    29.631308            0.545455    0.379585   34.385399\n",
      "std     12.511818            1.151090    0.792999   54.597730\n",
      "min      0.750000            0.000000    0.000000    0.000000\n",
      "25%     23.000000            0.000000    0.000000    7.895800\n",
      "50%     28.000000            0.000000    0.000000   15.045800\n",
      "75%     35.000000            1.000000    0.000000   31.387500\n",
      "max     80.000000            8.000000    5.000000  512.329200\n",
      "\n",
      "Datase Shape 확인\n",
      "Train Data Shape (627, 9)\n",
      "Test Data Shape (264, 9)\n",
      "\n",
      "Age Histogram\n",
      "Sex Plot\n",
      "Selected Data Visualization\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, '% survive')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAAIWCAYAAABTOFfKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3dfZhlZXnn++9PG9EAAypYpwVMqWl1DChoBzUvniIaRUkAoyEyROnIoeOJmvGkyQxoYkgYk07UGHNi0HZ0wFwG8IUoIybEoBUnjqKNKC8CitKOdBB8wZaWDMeGe/7Yq+ds26ruXXRV7b2e+n6uq65eL8/e+75rVa/+9XrWrp2qQpIkqWUPGHcBkiRJS83AI0mSmmfgkSRJzTPwSJKk5hl4JElS8ww8kiSpeavGXcB8khwOvBuYAgrYVFVvSfIw4GJgGtgCnFxVdyYJ8Bbg+cDdwLqq+tzuXuPggw+u6enpefd///vfZ7/99tv7ZiZEa/1Aez211g+M3tNVV131rao6ZBlKWlR7Oo9IWj67O49MbOABdgAbqupzSQ4ArkryUWAdcEVVbUxyFnAW8B+B5wFruq+nAed1f85renqazZs3z7t/dnaWmZmZRWhlMrTWD7TXU2v9wOg9Jfna0lez+PZ0HpG0fHZ3HpnYKa2qum3nFZqqugu4ATgUOBG4oBt2AXBSt3wi8O4a+DRwUJLVy1y2JEmaQBMbeIYlmQaOBq4Epqrqtm7XNxhMecEgDH196GG3dtskSdIKN8lTWgAk2R/4APDqqvre4FadgaqqJAv6bIwk64H1AFNTU8zOzs47dvv27bvd3zet9QPt9dRaP9BmT5L6Z6IDT5J9GISd91TVJd3m25OsrqrbuimrO7rtW4HDhx5+WLfth1TVJmATwNq1a2t39xa0dj9Fa/1Aez211g+02ZOk/pnYKa3uXVfvBG6oqj8b2nUpcFq3fBrwoaHtL83A04FtQ1NfkiRpBZvkKzw/A7wEuDbJ57ttrwE2Au9NcjrwNeDkbt9HGLwl/WYGb0v/9eUtV5IkTaqJDTxV9c9A5tn9rDnGF/CKJS1KkiT10sROaUmSJC2Wib3Co/GbPuuykcdu2Xj8ElYiSdLe8QqPJElqnoFHkiQ1z8AjSZKaZ+CRJEnNM/BIkqTmGXgkSVLzDDySJKl5Bh5JktQ8A48kSWqegUeSJDXPwCNJkppn4JEkSc0z8EiSpOYZeCRJUvMMPJIkqXkGHkmS1LxV4y5Akvrs2q3bmD7rsnGXoUWwZePx4y5BS2hir/AkeVeSO5JcN7Tt4iSf7762JPl8t306yb8O7Xvb+CqXJEmTZpKv8JwP/CXw7p0bqupXdy4neROwbWj8V6rqqGWrTpIk9cbEBp6q+kSS6bn2JQlwMvDzy1mTJEnqp4kNPHvwc8DtVfXloW2PTnI18D3gd6vqv831wCTrgfUAU1NTzM7Ozvsi27dv3+3+vlloPxuO3DHy2HF9n1b6MeqDFnuS1D99DTynABcOrd8GPKqqvp3kqcAHk/xkVX1v1wdW1SZgE8DatWtrZmZm3heZnZ1ld/v7ZqH9rFvAjZhbTh39eRfTSj9GfdBiT5L6Z2JvWp5PklXALwMX79xWVfdU1be75auArwCPG0+FkiRp0vQu8ADPBm6sqlt3bkhySJIHdsuPAdYAXx1TfZIkacJMbOBJciHwKeDxSW5Ncnq368X88HQWwDOBa7q3qb8feHlVfWf5qpUkSZNsYu/hqapT5tm+bo5tHwA+sNQ1SZKkfprYKzySJEmLxcAjSZKaZ+CRJEnNM/BIkqTmGXgkSVLzDDySJKl5Bh5JktQ8A48kSWqegUeSJDXPwCNJkppn4JEkSc0z8EiSpOYZeCRJUvMMPJIkqXkGHkmS1DwDj6SJleS3ktyQ5D1L9PznJDlzKZ5b0mRZNe4CJGk3fhN4dlXdOu5CJPWbgUfSREryNuAxwN8luQh4LHAEsA9wTlV9KMk64CRgP2AN8EbgQcBLgHuA51fVd5KcAazv9t0MvKSq7t7l9R4LvBU4BLgbOKOqblzyRiUti4md0kryriR3JLluaNs5SbYm+Xz39fyhfWcnuTnJTUmeO56qJS2Wqno58C/AsQwCzceq6phu/Q1J9uuGHgH8MvBTwOuBu6vqaOBTwEu7MZdU1U9V1ZOBG4DT53jJTcCrquqpwJnAX81XW5L1STYn2Xzv3dv2tlVJy2CSr/CcD/wl8O5dtr+5qt44vCHJE4EXAz8JPBL4xySPq6p7l6NQSUvuOcAJQ/fbPBh4VLf88aq6C7gryTbgv3bbrwWe1C0fkeQ/AQcB+wOXDz95kv2Bnwbel2Tn5n3nK6aqNjEISOy7ek3tRV+SlsnEBp6q+kSS6RGHnwhcVFX3ALckuRk4hsH/8CT1X4AXVtVNP7QxeRqDqaud7htav4///xx3PnBSVX2hmwab2eX5HwB8t6qOWtyyJU2KiQ08u/HKJC8FNgMbqupO4FDg00Njbu22/Ygk6xnM5TM1NcXs7Oy8L7R9+/bd7u+bhfaz4cgdI48d1/dppR+jPlikni4HXpXkVVVVSY6uqqsX8PgDgNuS7AOcCmwd3llV30tyS5Jfqar3ZXCZ50lV9YW9LVzSZOhb4DkPOBeo7s83AS9byBMMX4peu3ZtzczMzDt2dnaW3e3vm4X2s+6sy0Yeu+XU0Z93Ma30Y9QHi9TTucCfA9ckeQBwC/CLC3j87wFXAt/s/jxgjjGnAucl+V0GN0ZfBBh4pEb0KvBU1e07l5O8A/hwt7oVOHxo6GHs8j84Sf1TVdNDq78xx/7zGUxX/cj44X1VdR6D/zDt+vhzhpZvAY7bu4olTaqJfZfWXJKsHlp9AbDzHVyXAi9Osm+SRzN4e+pnlrs+SZI0mSb2Ck+SCxncWHhwkluB3wdmkhzFYEprC93/+Krq+iTvBb4I7ABe4Tu0JEnSThMbeKrqlDk2v3M341/P4HdwSJIk/ZBeTWlJkiTdHwYeSZLUPAOPJElqnoFHkiQ1z8AjSZKaZ+CRJEnNM/BIkqTmGXgkSVLzDDySJKl5Bh5JktQ8A48kSWqegUeSJDXPwCNJkppn4JEkSc0z8EiSpOYZeCRJUvMMPJIkqXkGHkmS1LyJDTxJ3pXkjiTXDW17Q5Ibk1yT5G+THNRtn07yr0k+3329bXyVS5KkSbNq3AXsxvnAXwLvHtr2UeDsqtqR5E+As4H/2O37SlUdtbwlSlrpjjz0QDZvPH7cZUjag4m9wlNVnwC+s8u2f6iqHd3qp4HDlr0wSZLUO5N8hWdPXgZcPLT+6CRXA98Dfreq/ttcD0qyHlgPMDU1xezs7LwvsH379t3u75uF9rPhyB17HtQZ1/dppR+jPmixJ0n908vAk+S1wA7gPd2m24BHVdW3kzwV+GCSn6yq7+362KraBGwCWLt2bc3MzMz7OrOzs+xuf98stJ91Z1028tgtp47+vItppR+jPmixJ0n9M7FTWvNJsg74ReDUqiqAqrqnqr7dLV8FfAV43NiKlCRJE6VXgSfJccB/AE6oqruHth+S5IHd8mOANcBXx1OlJEmaNBM7pZXkQmAGODjJrcDvM3hX1r7AR5MAfLqqXg48E/jDJD8A7gNeXlXfmfOJJUnSijOxgaeqTplj8zvnGfsB4ANLW5EkSeqrXk1pSZIk3R8GHkmS1DwDjyRJap6BR5IkNc/AI0mSmmfgkSRJzTPwSJKk5hl4JElS8ww8kiSpeQYeSZLUPAOPJElqnoFHkiQ1z8AjSZKaZ+CRJEnNM/BIkqTmGXgkSVLzDDySJKl5Bh5JktS8iQ08Sd6V5I4k1w1te1iSjyb5cvfnQ7vtSfIXSW5Ock2Sp4yvckmSNGkmNvAA5wPH7bLtLOCKqloDXNGtAzwPWNN9rQfOW6YaJUlSD0xs4KmqTwDf2WXzicAF3fIFwElD299dA58GDkqyenkqlSRJk25iA888pqrqtm75G8BUt3wo8PWhcbd22yRJklg17gLur6qqJLXQxyVZz2Dai6mpKWZnZ+cdu3379t3u75uF9rPhyB0jjx3X92mlH6M+aLEnSf3Tt8Bze5LVVXVbN2V1R7d9K3D40LjDum0/oqo2AZsA1q5dWzMzM/O+2OzsLLvb3zcL7WfdWZeNPHbLqaM/72Ja6ceoD1rsSVL/9G1K61LgtG75NOBDQ9tf2r1b6+nAtqGpL0mStMJN7BWeJBcCM8DBSW4Ffh/YCLw3yenA14CTu+EfAZ4P3AzcDfz6shcsSZIm1sQGnqo6ZZ5dz5pjbAGvWNqKJElSX/VtSkuSJGnBDDySJKl5Bh5JktQ8A48kSWqegUeSJDXPwCNJkppn4JEkSc0z8EiSpOYZeCRJUvMMPJIkqXkGHkmS1DwDjyRJap6BR5IkNc/AI0mSmmfgkSRJzTPwSJKk5hl4JElS8ww8kiSpeQYeSZLUvFXjLmChkjweuHho02OA1wEHAWcA3+y2v6aqPrLM5UmSpAnUu8BTVTcBRwEkeSCwFfhb4NeBN1fVG8dYniRJmkC9Czy7eBbwlar6WpJx1yJpBbp26zamz7ps3GVIzdqy8fhFeZ6+B54XAxcOrb8yyUuBzcCGqrpz1wckWQ+sB5iammJ2dnbeJ9++fftu9/fNQvvZcOSOkceO6/u00o9RH7TYk6T+6W3gSfIg4ATg7G7TecC5QHV/vgl42a6Pq6pNwCaAtWvX1szMzLyvMTs7y+72981C+1m3gP+1bjl19OddTCv9GPVBiz1J6p8+v0vrecDnqup2gKq6varurar7gHcAx4y1OkmSNDH6HHhOYWg6K8nqoX0vAK5b9ookSdJE6uWUVpL9gF8AfmNo858mOYrBlNaWXfZJkqQVrJeBp6q+Dzx8l20vGVM5kiRpwvV5SkuSJGkkBh5JktQ8A48kSWqegUeSJDXPwCNJkprXy3dpae/4uT+SpJXGKzySJKl5Bh5JktQ8A48kSWqegUeSJDXPwCNJkppn4JEkSc3zbelaFIv9VvctG49f1OeTJK1sXuGRJEnNM/BIkqTmGXgkSVLzDDySJKl53rTckD3dOLzhyB2s83O0pB+SZAY4s6p+cdy1SFo6vQw8SbYAdwH3Ajuqam2ShwEXA9PAFuDkqrpzXDVKkqTJ0ecprWOr6qiqWtutnwVcUVVrgCu6dUkrQJLpJDcmOT/Jl5K8J8mzk3wyyZeTHNN9fSrJ1Un+e5LHz/E8+yV5V5LPdONOHEc/khZfnwPPrk4ELuiWLwBOGmMtkpbfTwBvAp7Qff074GeBM4HXADcCP1dVRwOvA/5ojud4LfCxqjoGOBZ4Q5L9dh2UZH2SzUk233v3tiVpRtLi6uWUFlDAPyQp4O1VtQmYqqrbuv3fAKbmemCS9cB6gKmpKWZnZ+d9ke3bt+92/6TZcOSO3e6fesiex0yKUb/vfTtGe9JaP7CsPd1SVdcCJLmewRXfSnItg6nuA4ELkqxhcA7ZZ47neA5wQpIzu/UHA48Cbhge1J1zNgHsu3pNLUEvkhZZXwPPz1bV1iSPAD6a5Mbhnd1Jbs6T0PCJau3atTUzMzPvi8zOzrK7/ZNmTzckbzhyB2+6th+HfMupMyON69sx2pPW+oFl7emeoeX7htbvY3CuOxf4eFW9IMk0MDvHcwR4YVXdtHRlShqHXk5pVdXW7s87gL8FjgFuT7IaoPvzjvFVKGkCHQhs7ZbXzTPmcuBVSQKQ5OhlqEvSMuhd4OluKjxg5zKDS9DXAZcCp3XDTgM+NJ4KJU2oPwX+OMnVzH91+1wGU13XdNNi5y5XcZKWVj/mN37YFPC33X/AVgF/U1V/n+SzwHuTnA58DTh5jDVKWkZVtQU4Ymh93Tz7Hjf0sN/t9s/STW9V1b8Cv7GEpUoak94Fnqr6KvDkObZ/G3jW8lckSZImXe+mtCRJkhbKwCNJkppn4JEkSc0z8EiSpOYZeCRJUvMMPJIkqXkGHkmS1DwDjyRJap6BR5IkNc/AI0mSmmfgkSRJzTPwSJKk5hl4JElS8ww8kiSpeavGXYA0l+mzLhtp3IYjdzCztKVIkhrgFR5JktQ8A48kSWqegUeSJDWvd/fwJDkceDcwBRSwqarekuQc4Azgm93Q11TVR8ZTpSbRqPcFAWzZePwSViJJWm69CzzADmBDVX0uyQHAVUk+2u17c1W9cYy1SZKkCdS7wFNVtwG3dct3JbkBOHS8VUmSpEnWu8AzLMk0cDRwJfAzwCuTvBTYzOAq0J3jq07SSnDkoQey2SlQaeKlqsZdw/2SZH/gn4DXV9UlSaaAbzG4r+dcYHVVvWyOx60H1gNMTU099aKLLpr3NbZv387++++/FOUviWu3btvt/qmHwO3/ukzFLJOph8AjHnbgSGP39P0ZduShoz3nYuvbz9woRu3p2GOPvaqq1i5DSYtq7dq1tXnz5nGXIQlIMu95pJdXeJLsA3wAeE9VXQJQVbcP7X8H8OG5HltVm4BNMDhRzczMzPs6s7OzzMzMjHyz67hvdF23hzo3HLmDN13by0M+rw1H7uDk3RzDYXv6/gzbcupoz7nYdv7MtaTFniT1T+/+9UsS4J3ADVX1Z0PbV3f39wC8ALhuHPWpDX0JuZKk0fQu8DC4V+clwLVJPt9tew1wSpKjGExpbQF+YzzlSZKkSdO7wFNV/wxkjl1N/s6dhfzumJXK75EkaU/8TcuSJKl5Bh5JktQ8A48kSWqegUeSJDXPwCNJkppn4JEkSc0z8EiSpOYZeCRJUvMMPJIkqXkGHkmS1LzefbREK/w4hJVl1OO94cgdzCxtKZK0InmFR5IkNc/AI0mSmmfgkSRJzfMenkXkfTmSJE0mA480YUYNzls2Hr/ElUhSO5zSkiRJzTPwSJKk5jmlJe2FPty3tZAanSaT1KqmAk+S44C3AA8E/nNVbRxzSdKS6UPYkqRJ0cyUVpIHAm8Fngc8ETglyRPHW5UkSZoELV3hOQa4uaq+CpDkIuBE4ItjrUpq0EKuLp1/3H5LWIkkjSZVNe4aFkWSFwHHVdX/1a2/BHhaVb1yl3HrgfXd6uOBm3bztAcD31qCcseltX6gvZ5a6wdG7+nHq+qQpS5msSW5i92fR/poJf8c9ok9/ah5zyMtXeEZSVVtAjaNMjbJ5qpau8QlLZvW+oH2emqtH2izp13c1Fp/LR4ze+qHpeypmXt4gK3A4UPrh3XbJEnSCtdS4PkssCbJo5M8CHgxcOmYa5IkSROgmSmtqtqR5JXA5Qzelv6uqrp+L592pKmvHmmtH2ivp9b6gTZ7GtZif/bUD/a0AM3ctCxJkjSflqa0JEmS5mTgkSRJzTPwzCPJcUluSnJzkrPGXc9CJTk8yceTfDHJ9Un+fbf9YUk+muTL3Z8PHXetC5HkgUmuTvLhbv3RSa7sjtPF3Q3rvZHkoCTvT3JjkhuSPKPPxyjJ/9P9vF2X5MIkD+77MZpPX88RSd6V5I4k1w1tm/NnLgN/0fV4TZKnjK/y+S30fNeHvrq/O59J8oWupz/ots/59ynJvt36zd3+6XHWvzujnscXuycDzxzSxsdU7AA2VNUTgacDr+h6OAu4oqrWAFd0633y74Ebhtb/BHhzVf0EcCdw+liquv/eAvx9VT0BeDKD3np5jJIcCvwWsLaqjmDw5oEX0/9j9CN6fo44Hzhul23z/cw9D1jTfa0HzlumGhdqoee7PvR1D/DzVfVk4CjguCRPZ/6/T6cDd3bb39yNm1SjnscXt6eq8muXL+AZwOVD62cDZ4+7rr3s6UPALzD4jbCru22rGfzStLHXN2IPhzE4af088GEgDH4j56q5jtukfwEHArfQvXlgaHsvjxFwKPB14GEM3gH6YeC5fT5Gu+m11+cIYBq4bmh9zp854O3AKXONm+SvPZ3v+tYX8GPA54Cnzff3icE7lJ/RLa/qxmUc9e6hl5HP44vdk1d45rbzxL3Trd22XuouAx4NXAlMVdVt3a5vAFNjKuv++HPgPwD3desPB75bVTu69b4dp0cD3wT+S3d59z8n2Y+eHqOq2gq8EfgfwG3ANuAq+n2M5tPUOYL5f+Z61+eI57te9NVN/XweuAP4KPAV5v/79L976vZvY3COnDQLOY8vak8GnsYl2R/4APDqqvre8L4axOZe/F6CJL8I3FFVV427lkW0CngKcF5VHQ18n12mr3p2jB7K4AN7Hw08EtiPH5060YTr08/crlo53+1UVfdW1VEMroocAzxhzCXtlXGfxw08c2viYyqS7MPgL/97quqSbvPtSVZ3+1cz+J9DH/wMcEKSLcBFDC6HvgU4KMnOX6DZt+N0K3BrVV3Zrb+fQQDq6zF6NnBLVX2zqn4AXMLguPX5GM2niXPEkPl+5nrT5wLPd73pC6Cqvgt8nMF0z3x/n/53T93+A4FvL3Ope7LQ8/ii9mTgmVvvP6YiSYB3AjdU1Z8N7boUOK1bPo3BXPfEq6qzq+qwqppmcDw+VlWnMjgJvKgb1pt+AKrqG8DXkzy+2/Qs4Iv09BgxmMp6epIf637+dvbT22O0G70/R+xivp+5S4GXdu9qejqwbWiKaGLcj/PdxPeV5JAkB3XLD2FwT9INzP/3abjXFzE4R07UFa37cR5f3J7GfQPTpH4Bzwe+xGDO9LXjrud+1P+zDC7fXgN8vvt6PoP5zyuALwP/CDxs3LXej95mgA93y48BPgPcDLwP2Hfc9S2wl6OAzd1x+iDw0D4fI+APgBuB64C/Bvbt+zHaTa+9PEcAFzK4x+oHDK4ynj7fzxyDG0rf2vV4LYN34I29hzl6WtD5rg99AU8Cru56ug54Xbd9zr9PwIO79Zu7/Y8Zdw976G+P5/HF7smPlpAkSc1zSkuSJDXPwCNJkppn4JEkSc0z8EiSpOYZeCRJUvMMPJIkqXkGHkmS1DwDjyRJap6BR5IkNc/AI0mSmmfgkSRJzTPwSJKk5hl4JElS8ww8kiSpeQYeSZLUPAOPJElqnoFHkiQ1z8AjSZKaZ+CRJEnNM/BIkqTmGXgkSVLzDDySJKl5Bh5JktQ8A48kSWqegUeSJDXPwCNJkppn4JEkSc1bNe4Cxunggw+u6enpcZchCbjqqqu+VVWHjLsOSW1a0YFnenqazZs3j7sMSUCSr427BkntckpLkiQ1z8AjSZKaZ+CRJEnNM/BIkqTmGXgkSVLzDDySJKl5Bh5JktQ8A48kSWqegUeSJDXPwCNJkppn4JEkSc0z8EiSpOYZeCRJUvMMPJIkqXkGHkmS1DwDjyRJap6BR5IkNc/AI0mSmmfgkSRJzTPwSJKk5hl4JElS8ww8kiSpeQYeSZLUPAOPJElqnoFHkiQ1z8AjSZKat2rcBYzTtVu3MX3WZeMuY69t2Xj8uEuQJGmieYVHkiQ1z8AjSZKaZ+CRJEnNM/BIkqTmGXgkSVLzDDySJKl5Bh5JktQ8A48kSWqegUeSJDXPwCNJkppn4JEkSc0z8EiSpOYZeCRJUvMMPJIkqXkGHkmS1DwDjyRJap6BR5IkNc/AI0mSmmfgkSRJzTPwSJKk5hl4JElS8ww8kiSpeQYeSZLUPAOPJElqXq8DT5KZJB8edx2SJGmy9TrwSJIkjWLsgSfJdJIbk5yf5EtJ3pPk2Uk+meTLSY7pvj6V5Ook/z3J4+d4nv2SvCvJZ7pxJ46jH0mSNHnGHng6PwG8CXhC9/XvgJ8FzgReA9wI/FxVHQ28DvijOZ7jtcDHquoY4FjgDUn223VQkvVJNifZfO/d25akGUmSNFlWjbuAzi1VdS1AkuuBK6qqklwLTAMHAhckWQMUsM8cz/Ec4IQkZ3brDwYeBdwwPKiqNgGbAPZdvaaWoBdJkjRhJiXw3DO0fN/Q+n0MajwX+HhVvSDJNDA7x3MEeGFV3bR0ZUqSpD6alCmtPTkQ2Notr5tnzOXAq5IEIMnRy1CXJEnqgb4Enj8F/jjJ1cx/VepcBlNd13TTYucuV3GSJGmypWrl3say7+o1tfq0Px93GXtty8bjx12CtNeSXFVVa8ddh6Q29eUKjyRJ0v1m4JEkSc0z8EiSpOYZeCRJUvMMPJIkqXkGHkmS1DwDjyRJap6BR5IkNc/AI0mSmmfgkSRJzTPwSJKk5hl4JElS8ww8kiSpeQYeSZLUPAOPJElqnoFHkiQ1z8AjSZKaZ+CRJEnNM/BIkqTmGXgkSVLzDDySJKl5Bh5JktS8VeMuYJyOPPRANm88ftxlSJKkJeYVHkmS1DwDjyRJap6BR5IkNc/AI0mSmmfgkSRJzTPwSJKk5hl4JElS8ww8kiSpeQYeSZLUPAOPJElqnoFHkiQ1z8AjSZKaZ+CRJEnNM/BIkqTmGXgkSVLzDDySJKl5Bh5JktQ8A48kSWqegUeSJDXPwCNJkppn4JEkSc0bKfAkOTfJqqH1f5PkvyxdWZIkSYtn1Cs8q4ArkzwpyS8AnwWuWrqyJEmSFs+qPQ+Bqjo7yT8CVwJ3As+sqpuXtDJJkqRFMuqU1jOBvwD+EJgF/t8kj1zCuiRJkhbNSFd4gDcCv1JVXwRI8svAx4AnLFVhkiRJi2XUwPOMqrp350pVXZLkn5aoJkmSpEU16k3LByd5Z5K/B0jyROCkpStLkiRp8YwaeM4HLgdWd+tfAl69FAVJkiQttpGv8FTVe4H7AKpqB3Dv7h8iSZI0GUYNPN9P8nCgAJI8Hdi2ZFVJkiQtolFvWv5t4FLgsUk+CRwCvGjJqpIkSVpEo17heSzwPOCnGdzL82VGD0uSJEljNWrg+b2q+h7wUOBY4K+A85asKkmSpEU0auDZeYPy8cA7quoy4EFLU5IkSdLiGjXwbE3yduBXgY8k2XcBj5UkSRqrUUPLyQzu3XluVX0XeBjwO0tWlSRJ0iIa9dPS7wYuGVq/DbhtqYqSJElaTE5LSZKk5hl4JElS8ww8kiSpeQYeSZLUPAOPJElqnoFHkiQ1z8AjSZKaZ+CRJEnNM/BIkqTmGXgkSVLzDDySJKl5Bh5JktQ8A48kSWqegUeSJDXPwCNJkppn4JEkSc1bNe4CxunarduYPuuycZchNWvLxuPHXYIkAV7hkSRJK4CBR5IkNc/AI0mSmmfgkSRJzTPwSJKk5hl4JElS8ww8kiSpeQYeSZLUPAOPJElqnj3XoYMAAAlhSURBVIFHkiQ1z8AjSZKaZ+CRJEnNM/BIkqTmGXgkSVLzDDySJKl5Bh5JktQ8A48kSWqegUeSJDXPwCNJkppn4JEkSc0z8EiSpOYZeCRJUvMMPJIkqXkGHkmS1LwlCzxJfivJDUnes0TPf06SM5fiuSVJUltWLeFz/ybw7Kq6dQlfQ5IkaY+WJPAkeRvwGODvklwEPBY4AtgHOKeqPpRkHXASsB+wBngj8CDgJcA9wPOr6jtJzgDWd/tuBl5SVXfv8nqPBd4KHALcDZxRVTcuRW+SJKl/lmRKq6peDvwLcCyDQPOxqjqmW39Dkv26oUcAvwz8FPB64O6qOhr4FPDSbswlVfVTVfVk4Abg9DlechPwqqp6KnAm8Ffz1ZZkfZLNSTbfe/e2vW1VkiT1wFJOae30HOCEofttHgw8qlv+eFXdBdyVZBvwX7vt1wJP6paPSPKfgIOA/YHLh588yf7ATwPvS7Jz877zFVNVmxgEJPZdvab2oi9JktQTyxF4Arywqm76oY3J0xhMXe1039D6fUO1nQ+cVFVf6KbBZnZ5/gcA362qoxa3bEmS1IrleFv65cCr0l1+SXL0Ah9/AHBbkn2AU3fdWVXfA25J8ivd8yfJk/eyZkmS1JDlCDznMrhZ+Zok13frC/F7wJXAJ4H5bkQ+FTg9yReA64ET72etkiSpQalaubex7Lt6Ta0+7c/HXYbUrC0bjx95bJKrqmrtEpYjaQXzNy1LkqTmGXgkSVLzDDySJKl5Bh5JktQ8A48kSWqegUeSJDXPwCNJkppn4JEkSc0z8EiSpOYZeCRJUvMMPJIkqXkGHkmS1DwDjyRJap6BR5IkNc/AI0mSmmfgkSRJzTPwSJKk5hl4JElS8ww8kiSpeQYeSZLUPAOPJElqnoFHkiQ1b9W4CxinIw89kM0bjx93GZIkaYl5hUeSJDXPwCNJkppn4JEkSc0z8EiSpOYZeCRJUvMMPJIkqXkGHkmS1DwDjyRJap6BR5IkNc/AI0mSmmfgkSRJzTPwSJKk5hl4JElS8ww8kiSpeQYeSZLUPAOPJElqnoFHkiQ1z8AjSZKaZ+CRJEnNM/BIkqTmGXgkSVLzDDySJKl5Bh5JktQ8A48kSWqegUeSJDXPwCNJkppn4JEkSc1LVY27hrFJchdw07jrWEIHA98adxFLpOXeYGX29+NVdcg4ipHUvlXjLmDMbqqqteMuYqkk2dxqfy33BvYnSYvNKS1JktQ8A48kSWreSg88m8ZdwBJrub+WewP7k6RFtaJvWpYkSSvDSr/CI0mSVoDmA0+S45LclOTmJGfNsX/fJBd3+69MMr38Vd5/I/T320m+mOSaJFck+fFx1Hl/7am/oXEvTFJJevXOn1H6S3JydwyvT/I3y13j3hjh5/NRST6e5OruZ/T546hTUvuantJK8kDgS8AvALcCnwVOqaovDo35TeBJVfXyJC8GXlBVvzqWghdoxP6OBa6sqruT/N/ATEv9deMOAC4DHgS8sqo2L3et98eIx28N8F7g56vqziSPqKo7xlLwAo3Y3ybg6qo6L8kTgY9U1fQ46pXUttav8BwD3FxVX62q/w+4CDhxlzEnAhd0y+8HnpUky1jj3thjf1X18aq6u1v9NHDYMte4N0Y5fgDnAn8C/M/lLG4RjNLfGcBbq+pOgL6Enc4o/RXwb7rlA4F/Wcb6JK0grQeeQ4GvD63f2m2bc0xV7QC2AQ9flur23ij9DTsd+LslrWhx7bG/JE8BDq+qy5azsEUyyvF7HPC4JJ9M8ukkxy1bdXtvlP7OAX4tya3AR4BXLU9pklaalf6blleMJL8GrAX+z3HXsliSPAD4M2DdmEtZSquANcAMg6tzn0hyZFV9d6xVLZ5TgPOr6k1JngH8dZIjquq+cRcmqS2tX+HZChw+tH5Yt23OMUlWMbis/u1lqW7vjdIfSZ4NvBY4oaruWabaFsOe+jsAOAKYTbIFeDpwaY9uXB7l+N0KXFpVP6iqWxjcE7NmmerbW6P0dzqDe5Soqk8BD2bwOVuStKhaDzyfBdYkeXSSBwEvBi7dZcylwGnd8ouAj1V/7uTeY39JjgbeziDs9On+D9hDf1W1raoOrqrp7kbXTzPosxc3LTPaz+cHGVzdIcnBDKa4vrqcRe6FUfr7H8CzAJL8WwaB55vLWqWkFaHpwNPdk/NK4HLgBuC9VXV9kj9MckI37J3Aw5PcDPw2MO9bnyfNiP29AdgfeF+SzyfZ9R+ciTVif701Yn+XA99O8kXg48DvVFUvrkCO2N8G4IwkXwAuBNb16D8cknqk6belS5IkQeNXeCRJksDAI0mSVgADjyRJap6BR5IkNc/AI0mSmmfg0ZJKckiSf05yXZKThrZ/KMkjl7mWjyQ5aDlfU5I0GQw8WmqnAG9j8EGSrwZI8ksMPiF70T8osvuE7jlV1fMb+kgGSdICGHi01H4A/BiwL3Bv9/Edrwb+dL4HJPmV7orQF5J8otu2LslfDo35cJKZbnl7kjd1v7zu7CTvGxo3k+TD3fKWJAcn2ZjkFUNjzklyZrf8O0k+m+SaJH+wiN8HSdIYGXi01P4GOBH4KPBHwG8Cf11Vd+/mMa8DnltVTwZG+Y3K+wFXduM3Ak9Lsl+371eBi3YZfzFw8tD6ycDFSZ7D4HOqjgGOAp6a5JkjvL4kacIZeLSkus+7Or6q1gKfA34JeH+SdyR5f/cJ2bv6JHB+kjOAeaeohtwLfKB7vR3A3wO/1F1NOh740C41XQ08IskjkzwZuLOqvg48p/u6uqv1CfTngzolSbuxatwFaEX5PeD1DO7r+Wfg/cAlwHOHB1XVy5M8jUFYuSrJU4Ed/HBAf/DQ8v+sqnuH1i9i8BlO3wE2V9Vdc9TyPgYfFvt/MLjiAxDgj6vq7fevPUnSpPIKj5ZFkjXAYVU1y+CenvuAAh4yx9jHVtWVVfU6Bp+cfTiwBTgqyQOSHM5g2mk+/wQ8BTiDH53O2uliBp/e/SIG4QcGH3L5siT7d3UcmuQRC+lTkjSZvMKj5fJ64LXd8oXABxl8Mv3r5hj7hi4gBbgC+EK3/Rbgiww+eftz871QVd3b3ai8DjhtnjHXJzkA2FpVt3Xb/iHJvwU+lQRgO/BrwB2jtylJmkR+WrokSWqeU1qSJKl5Bh5JktQ8A48kSWqegUeSJDXPwCNJkppn4JEkSc0z8EiSpOYZeCRJUvP+F4irJKiTM+pbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 648x648 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dataset 확인\n",
    "print('Dataset 확인')\n",
    "print(dftrain.head())\n",
    "print()\n",
    "\n",
    "# Label 확인\n",
    "print('Label 확인')\n",
    "print(y_train.head())\n",
    "print()\n",
    "\n",
    "# Dataset 상세 정보 확인(Numberic Feature들의 상세 정보를 출력해준다.)\n",
    "print('Dataset 상세 정보 확인')\n",
    "print(dftrain.describe())\n",
    "print()\n",
    "\n",
    "# Dataset Shape 확인\n",
    "print('Datase Shape 확인')\n",
    "print('Train Data Shape', dftrain.shape)\n",
    "print('Test Data Shape', dfeval.shape)\n",
    "print()\n",
    "\n",
    "plt.figure(figsize=(9,9))\n",
    "# Histogram 그리기\n",
    "plt.subplot(221)\n",
    "print('Age Histogram')\n",
    "dftrain['age'].hist(bins=20)\n",
    "\n",
    "# Plt 그리기\n",
    "plt.subplot(222)\n",
    "print('Sex Plot')\n",
    "dftrain.sex.value_counts().plot(kind='barh')\n",
    "\n",
    "# 조건으로서 Data Select하기\n",
    "plt.subplot(223)\n",
    "print('Selected Data Visualization')\n",
    "pd.concat([dftrain, y_train], axis=1).groupby('sex').survived.mean().plot(kind='barh').set_xlabel('% survive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base Feature Columns\n",
    "위에서 언급한 Feature Columns와 Input Function을 정의한다.  \n",
    "크게 다음과 같은 2가지 방식으로서 Ipnput Data를 변형 시킨뒤 사용한다.  \n",
    "- <code>tf.feature_column.numeric_column()</code>: Numeric Data는 tf.feature_column.numeric_columns를 활용하여 사용한다.\n",
    "- <code>tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary)</code>: Categorical Data는 One-Hot-Encoding으로서 변경한 뒤 사용한다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Columns\n",
      "VocabularyListCategoricalColumn(key='sex', vocabulary_list=('male', 'female'), dtype=tf.string, default_value=-1, num_oov_buckets=0)\n",
      "VocabularyListCategoricalColumn(key='n_siblings_spouses', vocabulary_list=(1, 0, 3, 4, 2, 5, 8), dtype=tf.int64, default_value=-1, num_oov_buckets=0)\n",
      "VocabularyListCategoricalColumn(key='parch', vocabulary_list=(0, 1, 2, 5, 3, 4), dtype=tf.int64, default_value=-1, num_oov_buckets=0)\n",
      "VocabularyListCategoricalColumn(key='class', vocabulary_list=('Third', 'First', 'Second'), dtype=tf.string, default_value=-1, num_oov_buckets=0)\n",
      "VocabularyListCategoricalColumn(key='deck', vocabulary_list=('unknown', 'C', 'G', 'A', 'B', 'D', 'F', 'E'), dtype=tf.string, default_value=-1, num_oov_buckets=0)\n",
      "VocabularyListCategoricalColumn(key='embark_town', vocabulary_list=('Southampton', 'Cherbourg', 'Queenstown', 'unknown'), dtype=tf.string, default_value=-1, num_oov_buckets=0)\n",
      "VocabularyListCategoricalColumn(key='alone', vocabulary_list=('n', 'y'), dtype=tf.string, default_value=-1, num_oov_buckets=0)\n",
      "NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='fare', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "\n",
      "Input Function Check\n",
      "Some feature keys: ['sex', 'age', 'n_siblings_spouses', 'parch', 'fare', 'class', 'deck', 'embark_town', 'alone']\n",
      "\n",
      "A batch of class: [b'First' b'Third' b'Third' b'First' b'Third' b'Third' b'First' b'Third'\n",
      " b'Third' b'Third']\n",
      "\n",
      "A batch of Labels: [0 1 0 1 0 0 1 0 1 1]\n",
      "\n",
      "Check Numeric Data(Age) Format After Data Preprocessing\n",
      "WARNING:tensorflow:Layer dense_features is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "[[65. ]\n",
      " [ 3. ]\n",
      " [40.5]\n",
      " [28. ]\n",
      " [28. ]\n",
      " [28. ]\n",
      " [35. ]\n",
      " [ 9. ]\n",
      " [17. ]\n",
      " [20. ]]\n",
      "\n",
      "Check Categorical Data(Gender) Format After Data Preprocessing\n",
      "WARNING:tensorflow:Layer dense_features_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:From /root/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4276: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /root/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4331: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature_columns 설정\n",
    "CATEGORICAL_COLUMNS = ['sex', 'n_siblings_spouses', 'parch', 'class', 'deck',\n",
    "                       'embark_town', 'alone']\n",
    "NUMERIC_COLUMNS = ['age', 'fare']\n",
    "\n",
    "feature_columns = []\n",
    "\n",
    "for feature_name in CATEGORICAL_COLUMNS:\n",
    "    vocabulary = dftrain[feature_name].unique()\n",
    "    feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary))\n",
    "\n",
    "for feature_name in NUMERIC_COLUMNS:\n",
    "    feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32))\n",
    "\n",
    "# Feature_columns 확인\n",
    "print('Feature Columns')\n",
    "for f_c in feature_columns:\n",
    "    print(f_c)\n",
    "print()\n",
    "\n",
    "\n",
    "# Input Function 선언 => Batch + Epoch만큼 Dataset을 가져온다.\n",
    "def make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=32):\n",
    "    def input_function():\n",
    "        ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))\n",
    "        if shuffle:\n",
    "            ds = ds.shuffle(1000)\n",
    "        ds = ds.batch(batch_size).repeat(num_epochs)\n",
    "        return ds\n",
    "    return input_function\n",
    "\n",
    "train_input_fn = make_input_fn(dftrain, y_train)\n",
    "eval_input_fn = make_input_fn(dfeval, y_eval, num_epochs=1, shuffle=False)\n",
    "\n",
    "# Input Function Check\n",
    "ds = make_input_fn(dftrain, y_train, batch_size=10)()\n",
    "print('Input Function Check')\n",
    "for feature_batch, label_batch in ds.take(1):\n",
    "    print('Some feature keys:', list(feature_batch.keys()))\n",
    "    print()\n",
    "    print('A batch of class:', feature_batch['class'].numpy())\n",
    "    print()\n",
    "    print('A batch of Labels:', label_batch.numpy())\n",
    "print()\n",
    "\n",
    "# Check Numeric Data Format After Data Preprocessing\n",
    "print('Check Numeric Data(Age) Format After Data Preprocessing')\n",
    "age_column = feature_columns[7]\n",
    "print(tf.keras.layers.DenseFeatures([age_column])(feature_batch).numpy())\n",
    "print()\n",
    "\n",
    "# Check Categorical Data Format After Data Preprocessing\n",
    "print('Check Categorical Data(Gender) Format After Data Preprocessing')\n",
    "gender_column = feature_columns[0]\n",
    "tf.keras.layers.DenseFeatures([tf.feature_column.indicator_column(gender_column)])(feature_batch).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 생성 및 결과 확인\n",
    "<code>tf.estimator.LinearClassifier()</code>를 활용하여 Model을 생성하고 결과를 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.77272725, 'accuracy_baseline': 0.625, 'auc': 0.8375268, 'auc_precision_recall': 0.7885603, 'average_loss': 0.47647125, 'label/mean': 0.375, 'loss': 0.4674509, 'precision': 0.7241379, 'prediction/mean': 0.33631855, 'recall': 0.6363636, 'global_step': 200}\n"
     ]
    }
   ],
   "source": [
    "linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns)\n",
    "linear_est.train(train_input_fn)\n",
    "result = linear_est.evaluate(eval_input_fn)\n",
    "\n",
    "clear_output()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an Estimator form a Keras model\n",
    "위에서 Estimator의 종류 중 하나로서 Keras Model도 소개하였다.  \n",
    "이러한 Keras또한 Tensorflow에서 지원하는 <code>tf.estimator</code>를 사용하여 구성할 수 있다.  \n",
    "<br>\n",
    "\n",
    "#### Create a simple Keras model\n",
    "간단한 Keras Model을 구성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 97\n",
      "Trainable params: 97\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(16, activation='relu', input_shape=(4,)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create an input function\n",
    "Iris Dataset을 다운받고 Dict Type으로서 설정하는 과정을 거친다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dense_input': <tf.Tensor: id=6964, shape=(32, 4), dtype=float32, numpy=\n",
      "array([[6.1, 2.8, 4.7, 1.2],\n",
      "       [5.7, 3.8, 1.7, 0.3],\n",
      "       [7.7, 2.6, 6.9, 2.3],\n",
      "       [6. , 2.9, 4.5, 1.5],\n",
      "       [6.8, 2.8, 4.8, 1.4],\n",
      "       [5.4, 3.4, 1.5, 0.4],\n",
      "       [5.6, 2.9, 3.6, 1.3],\n",
      "       [6.9, 3.1, 5.1, 2.3],\n",
      "       [6.2, 2.2, 4.5, 1.5],\n",
      "       [5.8, 2.7, 3.9, 1.2],\n",
      "       [6.5, 3.2, 5.1, 2. ],\n",
      "       [4.8, 3. , 1.4, 0.1],\n",
      "       [5.5, 3.5, 1.3, 0.2],\n",
      "       [4.9, 3.1, 1.5, 0.1],\n",
      "       [5.1, 3.8, 1.5, 0.3],\n",
      "       [6.3, 3.3, 4.7, 1.6],\n",
      "       [6.5, 3. , 5.8, 2.2],\n",
      "       [5.6, 2.5, 3.9, 1.1],\n",
      "       [5.7, 2.8, 4.5, 1.3],\n",
      "       [6.4, 2.8, 5.6, 2.2],\n",
      "       [4.7, 3.2, 1.6, 0.2],\n",
      "       [6.1, 3. , 4.9, 1.8],\n",
      "       [5. , 3.4, 1.6, 0.4],\n",
      "       [6.4, 2.8, 5.6, 2.1],\n",
      "       [7.9, 3.8, 6.4, 2. ],\n",
      "       [6.7, 3. , 5.2, 2.3],\n",
      "       [6.7, 2.5, 5.8, 1.8],\n",
      "       [6.8, 3.2, 5.9, 2.3],\n",
      "       [4.8, 3. , 1.4, 0.3],\n",
      "       [4.8, 3.1, 1.6, 0.2],\n",
      "       [4.6, 3.6, 1. , 0.2],\n",
      "       [5.7, 4.4, 1.5, 0.4]], dtype=float32)>}\n",
      "tf.Tensor([1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0], shape=(32,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "def input_fn():\n",
    "    split = tfds.Split.TRAIN\n",
    "    dataset = tfds.load('iris', split=split, as_supervised=True)\n",
    "    dataset = dataset.map(lambda features, labels: ({'dense_input':features}, labels))\n",
    "    dataset = dataset.batch(32).repeat()\n",
    "    return dataset\n",
    "\n",
    "# Chek Data\n",
    "for features_batch, labels_batch in input_fn().take(1):\n",
    "    print(features_batch)\n",
    "    print(labels_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create an Estimator form the tf.keras model\n",
    "Keras Model을 <code>tf.keras.estimator.model_to_estimator</code>를 통하여 <code>tf.estimator</code>로서 변경하여 결과를 확인한다.  \n",
    "결과 Directory를 확인하면 다음과 같다.  \n",
    "**./Model/tfkeras_example/**  \n",
    "<div><img src=\"https://raw.githubusercontent.com/wjddyd66/wjddyd66.github.io/master/static/img/Tensorflow/32.png\" height=\"250\" width=\"400\" /></div><br>\n",
    "\n",
    "**./Model/tfkeras_example/Keras**  \n",
    "<div><img src=\"https://raw.githubusercontent.com/wjddyd66/wjddyd66.github.io/master/static/img/Tensorflow/33.png\" height=\"250\" width=\"400\" /></div><br>\n",
    "위에서 Keras -> Estimator로서 변경하였으므로 Keras Model을 사용할 수 있는 Folder와 Data 전처리 + Keras Model 인 Estimator를 사용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using the Keras model provided.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using the Keras model provided.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': './Model/tfkeras_example/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f95f0de4c10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': './Model/tfkeras_example/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f95f0de4c10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='./Model/tfkeras_example/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='./Model/tfkeras_example/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Warm-starting from: ./Model/tfkeras_example/keras/keras_model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Warm-starting from: ./Model/tfkeras_example/keras/keras_model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Warm-starting variables only in TRAINABLE_VARIABLES.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Warm-starting variables only in TRAINABLE_VARIABLES.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Warm-started 4 variables.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Warm-started 4 variables.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./Model/tfkeras_example/model.ckpt-50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./Model/tfkeras_example/model.ckpt-50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 50 into ./Model/tfkeras_example/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 50 into ./Model/tfkeras_example/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 109.38061, step = 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 109.38061, step = 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 75 into ./Model/tfkeras_example/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 75 into ./Model/tfkeras_example/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 84.006805.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 84.006805.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2019-12-28T13:48:31Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2019-12-28T13:48:31Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./Model/tfkeras_example/model.ckpt-75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./Model/tfkeras_example/model.ckpt-75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [1/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [1/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [2/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [2/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [3/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [3/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [4/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [4/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [5/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [5/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [6/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [6/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [7/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [7/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [8/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [8/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [9/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [9/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [10/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [10/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2019-12-28-13:48:31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2019-12-28-13:48:31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 75: global_step = 75, loss = 100.03222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 75: global_step = 75, loss = 100.03222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 75: ./Model/tfkeras_example/model.ckpt-75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 75: ./Model/tfkeras_example/model.ckpt-75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval result: {'loss': 100.03222, 'global_step': 75}\n"
     ]
    }
   ],
   "source": [
    "model_dir = \"./Model/tfkeras_example/\"\n",
    "keras_estimator = tf.keras.estimator.model_to_estimator(\n",
    "    keras_model=model, model_dir=model_dir)\n",
    "\n",
    "keras_estimator.train(input_fn=input_fn, steps=25)\n",
    "eval_result = keras_estimator.evaluate(input_fn=input_fn, steps=10)\n",
    "print('Eval result: {}'.format(eval_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Estimator 사용 결과 Keras에 익숙해져 있어서 인지 Keras가 더 편하고 자주 사용할 거이라고 생각된다...**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
